{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5ae79d0",
   "metadata": {
    "papermill": {
     "duration": 0.00497,
     "end_time": "2024-04-26T19:13:28.599997",
     "exception": false,
     "start_time": "2024-04-26T19:13:28.595027",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Real-Time Hand Gesture Recognition Project using Mediapipe and OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed0cf82",
   "metadata": {
    "papermill": {
     "duration": 0.004184,
     "end_time": "2024-04-26T19:13:28.608962",
     "exception": false,
     "start_time": "2024-04-26T19:13:28.604778",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This project aims to develop a real-time hand gesture recognition system using the MediaPipe library and OpenCV.\n",
    "The goal is to accurately detect and classify hand gestures, particularly the number of opened fingers, in real-time video streams. Hand gesture recognition has applications in sign language translation, virtual reality, robotics, and human-computer interaction. Through this project, we aim to showcase the potential of intuitive hand gestures for seamless interaction with devices and applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b30402",
   "metadata": {
    "papermill": {
     "duration": 0.004892,
     "end_time": "2024-04-26T19:13:28.618279",
     "exception": false,
     "start_time": "2024-04-26T19:13:28.613387",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Content**\n",
    "\n",
    "1. [Installing and Importing Libraries](#1.)\n",
    "1. [Implementation of Hand Gesture Recognition System](#2.)\n",
    "1. [Code Explanation](#3.)\n",
    "1. [Sample Outputs](#4.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be130635",
   "metadata": {
    "papermill": {
     "duration": 0.004477,
     "end_time": "2024-04-26T19:13:28.627493",
     "exception": false,
     "start_time": "2024-04-26T19:13:28.623016",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"1.\"></a> \n",
    "# Installing and Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86971377",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T19:13:28.638462Z",
     "iopub.status.busy": "2024-04-26T19:13:28.638012Z",
     "iopub.status.idle": "2024-04-26T19:13:47.894412Z",
     "shell.execute_reply": "2024-04-26T19:13:47.893087Z"
    },
    "papermill": {
     "duration": 19.26523,
     "end_time": "2024-04-26T19:13:47.897279",
     "exception": false,
     "start_time": "2024-04-26T19:13:28.632049",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mediapipe\r\n",
      "  Downloading mediapipe-0.10.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\r\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.10/site-packages (4.9.0.80)\r\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from mediapipe) (1.4.0)\r\n",
      "Requirement already satisfied: attrs>=19.1.0 in /opt/conda/lib/python3.10/site-packages (from mediapipe) (23.2.0)\r\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /opt/conda/lib/python3.10/site-packages (from mediapipe) (23.5.26)\r\n",
      "Requirement already satisfied: jax in /opt/conda/lib/python3.10/site-packages (from mediapipe) (0.4.26)\r\n",
      "Requirement already satisfied: jaxlib in /opt/conda/lib/python3.10/site-packages (from mediapipe) (0.4.26)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from mediapipe) (3.7.5)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from mediapipe) (1.26.4)\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from mediapipe) (2.1.2+cpu)\r\n",
      "Requirement already satisfied: opencv-contrib-python in /opt/conda/lib/python3.10/site-packages (from mediapipe) (4.9.0.80)\r\n",
      "Requirement already satisfied: protobuf<4,>=3.11 in /opt/conda/lib/python3.10/site-packages (from mediapipe) (3.20.3)\r\n",
      "Collecting sounddevice>=0.4.4 (from mediapipe)\r\n",
      "  Downloading sounddevice-0.4.6-py3-none-any.whl.metadata (1.4 kB)\r\n",
      "Requirement already satisfied: CFFI>=1.0 in /opt/conda/lib/python3.10/site-packages (from sounddevice>=0.4.4->mediapipe) (1.16.0)\r\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from jax->mediapipe) (0.2.0)\r\n",
      "Requirement already satisfied: opt-einsum in /opt/conda/lib/python3.10/site-packages (from jax->mediapipe) (3.3.0)\r\n",
      "Requirement already satisfied: scipy>=1.9 in /opt/conda/lib/python3.10/site-packages (from jax->mediapipe) (1.11.4)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mediapipe) (1.2.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mediapipe) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mediapipe) (4.47.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mediapipe) (1.4.5)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mediapipe) (21.3)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mediapipe) (9.5.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mediapipe) (3.1.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mediapipe) (2.9.0.post0)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->mediapipe) (3.13.1)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->mediapipe) (4.9.0)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->mediapipe) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->mediapipe) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->mediapipe) (3.1.2)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->mediapipe) (2024.2.0)\r\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->mediapipe) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->mediapipe) (1.3.0)\r\n",
      "Downloading mediapipe-0.10.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading sounddevice-0.4.6-py3-none-any.whl (31 kB)\r\n",
      "Installing collected packages: sounddevice, mediapipe\r\n",
      "Successfully installed mediapipe-0.10.11 sounddevice-0.4.6\r\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48a55cfd",
   "metadata": {
    "papermill": {
     "duration": 15.523974,
     "end_time": "2024-04-26T19:14:03.428446",
     "exception": false,
     "start_time": "2024-04-26T19:13:47.904472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458a272b",
   "metadata": {
    "papermill": {
     "duration": 0.006973,
     "end_time": "2024-04-26T19:14:03.442851",
     "exception": false,
     "start_time": "2024-04-26T19:14:03.435878",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"2.\"></a> \n",
    "# Implementation of Hand Gesture Recognition System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "913aa7cd",
   "metadata": {
    "papermill": {
     "duration": 0.016579,
     "end_time": "2024-04-26T19:14:03.466704",
     "exception": false,
     "start_time": "2024-04-26T19:14:03.450125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72e0fd08",
   "metadata": {
    "papermill": {
     "duration": 0.018587,
     "end_time": "2024-04-26T19:14:03.492803",
     "exception": false,
     "start_time": "2024-04-26T19:14:03.474216",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to count opened fingers for both hands\n",
    "def count_opened_fingers(hand_landmarks):\n",
    "    \n",
    "    # Define finger landmark indices\n",
    "    finger_tip_indices = [4, 8, 12, 16, 20]\n",
    "    \n",
    "    # Count opened fingers\n",
    "    opened_fingers = 0\n",
    "    \n",
    "    for finger_tip_index in finger_tip_indices:\n",
    "        \n",
    "        # Check if the finger is opened (y-coordinate of finger tip landmark is higher than y-coordinate of its adjacent landmark)\n",
    "        if hand_landmarks.landmark[finger_tip_index].y < hand_landmarks.landmark[finger_tip_index - 1].y:\n",
    "            opened_fingers += 1\n",
    "    \n",
    "     # Return 0 if no fingers are opened\n",
    "    if opened_fingers == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return opened_fingers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc706883",
   "metadata": {
    "papermill": {
     "duration": 0.106728,
     "end_time": "2024-04-26T19:14:03.607017",
     "exception": false,
     "start_time": "2024-04-26T19:14:03.500289",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_hands.Hands(min_detection_confidence=0.8, min_tracking_confidence=0.5, max_num_hands=2) as hands:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert BGR to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Flip image horizontally\n",
    "        image = cv2.flip(image, 1)\n",
    "        \n",
    "        # Set flag\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        # Detections\n",
    "        results = hands.process(image)\n",
    "        \n",
    "        # Set flag to true\n",
    "        image.flags.writeable = True\n",
    "\n",
    "        # RGB 2 BGR\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        if results.multi_hand_landmarks:\n",
    "            total_opened_fingers = 0\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                \n",
    "                # Draw hand landmarks\n",
    "                mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "                \n",
    "                # Count opened fingers for each hand\n",
    "                opened_fingers = count_opened_fingers(hand_landmarks)\n",
    "                \n",
    "                # Accumulate total opened fingers\n",
    "                total_opened_fingers += opened_fingers\n",
    "                \n",
    "                # Display count on screen for each hand\n",
    "                cv2.putText(image, str(opened_fingers),\n",
    "                            (int(hand_landmarks.landmark[0].x * image.shape[1]),\n",
    "                             int(hand_landmarks.landmark[0].y * image.shape[0]) + 30),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (84, 44, 0), 2, cv2.LINE_AA)\n",
    "        \n",
    "         # Display total count for both hands\n",
    "            if total_opened_fingers == 10:\n",
    "                cv2.putText(image, \"10\", (570, 50),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (84, 44, 0), 2, cv2.LINE_AA)\n",
    "            else:\n",
    "                cv2.putText(image, str(total_opened_fingers), (570, 50),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (84, 44, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Rendering results\n",
    "        if results.multi_hand_landmarks:\n",
    "            for num, hand in enumerate(results.multi_hand_landmarks):\n",
    "                mp_drawing.draw_landmarks(image, hand, mp_hands.HAND_CONNECTIONS, \n",
    "                                        mp_drawing.DrawingSpec(color=(26, 0, 197),\n",
    "                                                               thickness=2, circle_radius=4),\n",
    "                                        mp_drawing.DrawingSpec(color=(246, 246, 253),\n",
    "                                                               thickness=2, circle_radius=2),\n",
    "                                         )\n",
    "        # Display image\n",
    "        cv2.imshow('Hand Tracking', image)\n",
    "\n",
    "        # Break loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# Release webcam and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()+"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d002a32b",
   "metadata": {
    "papermill": {
     "duration": 0.00742,
     "end_time": "2024-04-26T19:14:03.622088",
     "exception": false,
     "start_time": "2024-04-26T19:14:03.614668",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"3.\"></a>\n",
    "# Code Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47428b54",
   "metadata": {
    "papermill": {
     "duration": 0.007439,
     "end_time": "2024-04-26T19:14:03.637556",
     "exception": false,
     "start_time": "2024-04-26T19:14:03.630117",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Code Explanation\n",
    "- **Initializing Webcam:** The `cv2.VideoCapture(0)` function initializes the webcam for capturing video frames.\n",
    "- **Hand Detection and Tracking:** Inside the `with mp_hands.Hands()` context manager, the code continuously captures frames from the webcam (`cap.read()`) and processes them using the MediaPipe `hands.process()` function to detect and track hand landmarks in each frame.\n",
    "- **Converting Color Spaces:** The captured frame is converted from BGR to RGB color space using `cv2.cvtColor()` because MediaPipe requires input images in RGB format.\n",
    "- **Flipping Image:** The captured image is horizontally flipped using `cv2.flip()` to correct for mirror effects.\n",
    "- **Disabling Writeable Flag:** The writeable flag of the image array is temporarily disabled to prevent accidental modifications during hand detection.\n",
    "- **Hand Landmark Detection:** The `hands.process()` function detects and tracks hand landmarks, and the results are stored in the `results` variable.\n",
    "- **Enabling Writeable Flag:** The writeable flag of the image array is re-enabled for further processing.\n",
    "- **Converting Color Spaces:** Before displaying the results, we convert the results from RGB back to BGR format because OpenCV is typically used for displaying images in BGR format.\n",
    "- **Rendering Results:** If hand landmarks are detected (`results.multi_hand_landmarks`), the code draws landmarks and hand connections on the image using `mp_drawing.draw_landmarks()`.\n",
    "- **Counting Opened Fingers:** The `count_opened_fingers()` function counts the number of opened fingers for each hand and displays the count on the image using `cv2.putText()`.\n",
    "- **Displaying Total Count:** The total count of opened fingers for both hands is displayed on the image.\n",
    "- **Displaying Image:** The processed image with hand landmarks and finger counts is displayed using `cv2.imshow()`.\n",
    "- **Breaking the Loop:** The loop breaks if the 'q' key is pressed (`cv2.waitKey(1) & 0xFF == ord('q')`).\n",
    "- **Releasing Resources:** Finally, the webcam is released (`cap.release()`) and all OpenCV windows are closed (`cv2.destroyAllWindows()`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a2b4e1",
   "metadata": {
    "papermill": {
     "duration": 0.007257,
     "end_time": "2024-04-26T19:14:03.652446",
     "exception": false,
     "start_time": "2024-04-26T19:14:03.645189",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"4.\"></a>\n",
    "# Sample Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2c0a9e",
   "metadata": {
    "papermill": {
     "duration": 0.008621,
     "end_time": "2024-04-26T19:14:03.668631",
     "exception": false,
     "start_time": "2024-04-26T19:14:03.660010",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "You can check the sample outputs in the inputs section."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4887602,
     "sourceId": 8239561,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 39.730102,
   "end_time": "2024-04-26T19:14:05.302202",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-26T19:13:25.572100",
   "version": "2.5.0"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
